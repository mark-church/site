---
title: "The Acceleration of Change"
date: 2019-04-30T14:35:19-07:00
draft: false
tags: ["Life", "Economics"]
---

The world is changing faster every day - that's a quote that people say a lot these days. I've never heard anyone dispute it. People generally accept it as an unfortunate fact and shrug it off, like we accept that weather gets worse in the winter. Between news about artificial intelligence, reusable space rockets, and ever thinner computers it certainly seems like the world is changing faster than ever, but is it actually? Or does it just feel like it?

Let's follow a thought experiment introduced by Northwestern Economics professor Robert Gordon.

It goes like this ….

- Imagine that it's 1910 and you are a mailman. A package arriving from the other coast may take a week by train before you deliver it by hand via an early model-T. One day you slip on ice, hit your head, and go in to a 50 year coma.
Now you've woken up an old man or woman in the year 1960. In a confused state, you leave the hospital to continue your mail route. You find that the model-T has been replaced with a much faster and more reliable mail truck that can go 60 MPH. Mail can be shipped quickly to almost any city in the US using trucking on the interstate system and packages from Europe now arrive on jets overnight. Standardized shipping containers make the delivery of goods even faster, allowing anything to be sent by ship, truck, or rail. Telephones are owned by every person in America, allowing any two people to communicate easily and cheaply without using mail at all.

- Now let's repeat the experiment. You're a mailman in 1960. You slip on the ice, hit your head, and wake up in 2010. Again you leave the hospital in a daze, but this time you find that your mail truck looks pretty much the same. It's a little bit more comfortable but it still goes the same speed. The shipping containers are the same dimensions that they were in 1960, express mail takes roughly the same amount of time to deliver cross country, and while jets are more reliable, they fly no faster than they did in 1960.

Let's make the example more realistic and look at how the aeronautical industry has progressed in 20th century. The biggest measure of progress in flight is speed and so we'll use that as our metric of innovation. 
In 1920 the average flight speed was around 100 mph. Through much scientific discovery and two major wars of military research funding, flight experienced an explosion of progress in the 1900s. By the 1960s commercial jets were cruising at over 600 mph. Flight speed tripled in  40 years, but in 2019 the average cruising speed of a commercial aircraft is less than it was in 1957. 

Of course there are numerous other areas of progress. The commercial flight industry is safer, more fuel efficient, and less expensive but most of these measures improved rapidly as well and then slowed after 1960. We briefly had commercial flight that topped 1,300 mph but low profit and popularity ended commercial supersonic flight in 2003. No which metric you take, there was far more technological progress from 1900–1960 than there has been in the next 60 years.

If progress is slowing, then why do our intuitions about technology make us feel that it's speeding up? The answer is compound interest.

### Technology's Compound Interest
In the realm of innovation, compound interest is the incremental increase in productivity of innovation due to improvements in the tools and processes of innovation. This means that if someone invents a better microscope that makes drug researchers two times as productive, then the drug researchers can invent new drugs twice as fast. An innovation in one area has led to an increasing rate of innovation for something else.

Software is often a tool for production so there are many examples of software increasing the rate of downstream innovation. Software changed dramatically from the 70s to the 90s. What started as assembly code morphed into higher level languages such as C (1972), C++ (1985), and Java (1995). Each was progressively easier to use and was more accessible to its users. Each enabled a larger group of people to innovate. The result was compound innovation - the tools of production improved and that improved the rate of production. These more approachable languages also increased the total production because more people were able to learn and use these tools.

This is a cycle that has repeated for centuries- hunting gave way to farming, which gave way to factory work, which gave way to white collar paperwork, which gave way to software. Maybe using aircraft speed is not a good approximation for progress and so we can look at a higher-level proxy such as national productivity. Even here though, we see some very curious trends that conflict with with our notions of progress.

### The Productivity Paradox
US Labor Productivity is a special number tracked by economists to measure, over time, the amount of work or output that a single worker is capable of. It's defined as the ratio of the national output (GDP) divided by the time worked (total hours worked by all people in the country).
There's an interesting trend in this number lately. The trend even has a name. Economists are calling it the Productivity Paradox. It's an apparent slowdown in Labor Productivity rates in the US. This raises the question, in a time when it's generally accepted that the steady flow of innovation has only been increasing, why are productivity rates falling? Let's take a look at the full history of US labor rates for a broader perspective.
Source: US Bureau of Labor StatisticsThe data is ripe with historical footnotes. That massive dip in the middle - that's the 1970s energy crisis. The massive spike in the early 50s - inexpensive automobiles, global peace, and US land left largely unaffected by WWII. The US was experiencing an explosion of productivity. The US national average from 1948 hovers around 2% each year.
Let's look at more recent history. The 1990s gave us PCs, spreadsheets, email, and office productivity posters. Productivity skyrocketed (along with the stock market), doubling the national average, and remained high through the early 2000s. But then something weird happens. Productivity drops back to 2% in 2005 and then averages at a measly 1.4% from 2005 until today. The 2000s gave us iPhones, Facebook, WiFi, Amazon, Twitter. So what happened? Well there are two common explanations, both of which could be partially true.
Innovations in the 2000s were largely consumer innovations and while they impacted our personal lives tremendously, they did little to improve productivity.
Society/life altering innovation truly did slow down in the 2000s which led to a drop in productivity rates.

- 1 is likely to a degree, but it's still difficult to explain the sudden and very long drought in worker productivity. There are hundreds if not thousands of new technology companies focused just on worker productivity (slack, gmail, video conferencing). It's hard to believe that the world stopped innovating in this area.
- 2 is difficult to explain. In war, famine, or disease, it's easy to see how productivity could drop, but in this case 2005–2017 has been some of the safest periods in recorded history by average measures. A massive global recession in 2008 sparked a recovery and brief jump to 3%+ in 2009 but by 2011 productivity was back to sub-zero percentages until now. It raises a very interesting question - is it even possible for innovation to slow down in modern society? Why is it so hard to believe that it could? The reason is because of compound interest.

### Defining Innovation
Innovation itself is an interesting and hard-to-pin-down concept which was the first of many new questions that the first one generated. We treat innovation like it's natural resource that flows from a pump, gets processed in a refinery, and then sprinkled on top of software to create a reliable flow of new products. However, innovation is just a word and a concept. It has no number or weight to directly measure. At best, we have proxies for innovation rates, like CPU frequency gains, increased fuel efficiency, or labor productivity. Innovation is simply a new way of doing things, which could be new sales strategies or new jet engines, which makes defining it a very fuzzy practice.

### A New Definition for Innovation
To explain this conflict we need a new definition for innovation:

>Innovation is the novel exploitation of natural phenomena, economic or societal structures, or means of production for gains in utility or value.

The key word is _exploitation._ Exploitation evokes an appropriate comparison to natural resources. Taking oil resources as an example, oil in the US was plentiful in the early 1900s. California was the top producing state and many of it's oil-rich regions were discovered through petroleum seep (an actual naturally occurring pond of surface oil) or through hand dug wells. As the easy to reach oil was exploited, rigs were invented to drill deeper, followed by offshore drilling, followed by even more extreme measures today like fracking. 

Innovation is an exploitation in the same manner. The difference is that it's exploitation of the potential combinations of matter, energy, and logic. Early lightbulbs had hundreds of different implementations. Edison's first bulbs had a 40 hour lifespan but incremental improvements were discovered in means of production and materials until we have the lightbulbs that we have today. The first LED was invented in 1927 and it remains the most technologically advanced lightbulb that we have today in 2018. 

Fire is an easily exploitable natural phenomena. You just have to rub two sticks together long enough and you get fire. This is why humans harnessed fire very early in human history. Lightbulbs were not as obvious, but were able to be discovered using the tools of the late 1800s. Lightbulbs are also an exploitation of a natural phenomena (electricity) that is combined with certain materials  to produce light. What's happened is that we have exploited most of the possible combinations of materials and means of production that exist for lightbulbs. The possible exploitations for lightbulbs are finite, just like a natural resource, and as the low hanging fruit is discovered, the remaining exploitations become more difficult and expensive to discover or require generational shifts in technology to reveal.